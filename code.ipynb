{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3zc7BJ3LjFPsra2lgwDug",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jiyabisht/Book_Recommender/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b5YGqX0XqRU",
        "outputId": "d5863b7f-1cc9-4601-91e9-acf8512c1a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries and handle the NumPy compatibility issue\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4\n",
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "Jbdq-jvZ8bFN",
        "outputId": "a3768db4-40ee-4fe3-916a-077fac4d5f42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "ef6b874543514759a0fec3b3afa7b54d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.12/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.16.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the full path to the single CSV file\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/book recom./BookCrossingThemes.csv'\n",
        "\n",
        "# Load the single dataset file with the correct separator (semicolon)\n",
        "df = pd.read_csv(file_path, sep=';', on_bad_lines='skip', encoding='latin-1')\n",
        "\n",
        "print(\"DataFrame loaded successfully with correct columns!\")\n",
        "print(df.columns)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGuoPsBD-HCx",
        "outputId": "30ffb5d0-4260-4dbc-dca1-eb091a6f792e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "DataFrame loaded successfully with correct columns!\n",
            "Index(['Book-Title', 'Book-Author', 'User-ID', 'ISBN', 'Book-Rating',\n",
            "       'Year-Of-Publication', 'Publisher', 'Location', 'Age', 'category',\n",
            "       'description', 'num_words', 'num_chars', 'cleaned_description',\n",
            "       'Theme'],\n",
            "      dtype='object')\n",
            "                                Book-Title       Book-Author  User-ID  \\\n",
            "0                         The Terminal Man  Michael Crichton   276964   \n",
            "1                              The Chamber      John Grisham   276964   \n",
            "2  The Girl Who Loved Tom Gordon : A Novel      Stephen King   276964   \n",
            "3                              In the Dark    Richard Laymon   276964   \n",
            "4                        Tailchaser's Song      Tad Williams   276964   \n",
            "\n",
            "        ISBN  Book-Rating  Year-Of-Publication                Publisher  \\\n",
            "0  345354621           10                 1988         Ballantine Books   \n",
            "1  440220602            9                 1995  Dell Publishing Company   \n",
            "2  684867621            8                 1999                 Scribner   \n",
            "3  843949163            8                 2001            Leisure Books   \n",
            "4  886773741            7                 1994                Daw Books   \n",
            "\n",
            "                     Location   Age          category  \\\n",
            "0  villa ridge, missouri, usa  34.0           Fiction   \n",
            "1  villa ridge, missouri, usa  34.0  American fiction   \n",
            "2  villa ridge, missouri, usa  34.0           Fiction   \n",
            "3  villa ridge, missouri, usa  34.0        California   \n",
            "4  villa ridge, missouri, usa  34.0           Fiction   \n",
            "\n",
            "                                         description  num_words  num_chars  \\\n",
            "0  Hearry Benson suffers from violent seizures. W...         54        335   \n",
            "1  While the executioners prepare the gas chamber...         26        155   \n",
            "2  A story of a nine year old who wanders off in ...         19         90   \n",
            "3  A tale of suspense follows young librarian Jan...         44        250   \n",
            "4  Fritti Tailchaser, a ginger tomcat of courage ...         31        199   \n",
            "\n",
            "                                 cleaned_description  \\\n",
            "0  hearry benson suffers violent seizure becomes ...   \n",
            "1  executioner prepare gas chamber protester gath...   \n",
            "2  story nine year old wanders wilderness area he...   \n",
            "3  tale suspense follows young librarian jane ker...   \n",
            "4  fritti tailchaser ginger tomcat courage curios...   \n",
            "\n",
            "                                 Theme  \n",
            "0               Psychological Thriller  \n",
            "1  Crime Thrillers and Detective Drama  \n",
            "2              Spiritual and Self-Help  \n",
            "3           Vampire/Paranormal Fantasy  \n",
            "4                       Cozy Mysteries  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The loaded DataFrame from the previous step is named 'df'\n",
        "\n",
        "# Clean up column names by stripping any leading or trailing whitespace\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Filter out users and books with a low number of interactions\n",
        "user_counts = df['User-ID'].value_counts()\n",
        "book_counts = df['Book-Title'].value_counts()\n",
        "active_users = user_counts[user_counts > 100].index\n",
        "popular_books = book_counts[book_counts > 50].index\n",
        "\n",
        "filtered_df = df[df['User-ID'].isin(active_users)]\n",
        "# Create a full copy to prevent the SettingWithCopyWarning\n",
        "final_data = filtered_df[filtered_df['Book-Title'].isin(popular_books)].copy()\n",
        "\n",
        "# Select only the columns needed for the collaborative filtering model\n",
        "model_data = final_data[['User-ID', 'Book-Title', 'Book-Rating']]\n",
        "\n",
        "print(\"Filtered Data:\")\n",
        "print(model_data.head())\n",
        "\n",
        "# Save the filtered data to a CSV file for later use in the web app\n",
        "final_data.to_csv('final_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaqMa7qe-Hj7",
        "outputId": "2e8e1cd5-baa9-4dc9-fd47-bf719ecd27e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Data:\n",
            "      User-ID                                         Book-Title  Book-Rating\n",
            "5020    21014                                     The Bean Trees            8\n",
            "5022    21014    Divine Secrets of the Ya-Ya Sisterhood: A Novel            8\n",
            "5023    21014                           Prodigal Summer: A Novel            8\n",
            "5035    21014  The Bad Beginning (A Series of Unfortunate Eve...            8\n",
            "5036    21014      Fried Green Tomatoes at the Whistle Stop Cafe            8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52981463",
        "outputId": "be0692d2-4bf6-4ade-9ff3-75121348ebfe"
      },
      "source": [
        "!pip install scikit-surprise"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.12/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.16.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader, SVD, dump\n",
        "from surprise.model_selection import train_test_split # Correct function name\n",
        "from surprise import accuracy\n",
        "\n",
        "# The Reader class parses the DataFrame, specifying the rating scale.\n",
        "reader = Reader(rating_scale=(1, 10))\n",
        "\n",
        "# Load the DataFrame into the Surprise Dataset format\n",
        "data = Dataset.load_from_df(model_data, reader)\n",
        "\n",
        "# Split the data into a training set and a testing set\n",
        "# CORRECTED LINE: Used 'train_test_split'\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Use the SVD algorithm, a popular matrix factorization technique.\n",
        "algo = SVD()\n",
        "\n",
        "# Train the model on the training data\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "predictions = algo.test(testset)\n",
        "print(\"Model accuracy (RMSE):\")\n",
        "accuracy.rmse(predictions)\n",
        "\n",
        "# Save the trained model to a file for later use in the web app\n",
        "dump.dump('book_recommender_model.pkl', algo=algo)\n",
        "print(\"Collaborative filtering model saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbP3I4_J-Vmv",
        "outputId": "9b3eed5e-c45d-41a6-88a4-57738fb83655"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy (RMSE):\n",
            "RMSE: 1.3662\n",
            "Collaborative filtering model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# Use the filtered data for this step\n",
        "# This variable should be available from the previous steps\n",
        "# A mapping from book title to its index in the DataFrame\n",
        "indices = pd.Series(final_data.index, index=final_data['Book-Title']).drop_duplicates()\n",
        "\n",
        "# Combine all content-based features into a single string for each book\n",
        "features = ['Theme', 'category', 'Book-Author', 'description']\n",
        "for feature in features:\n",
        "    if feature in final_data.columns:\n",
        "        final_data[feature] = final_data[feature].fillna('')\n",
        "\n",
        "def create_combined_features(row):\n",
        "    return ' '.join(str(row[f]) for f in features)\n",
        "\n",
        "final_data['combined_features'] = final_data.apply(create_combined_features, axis=1)\n",
        "\n",
        "# Create the TF-IDF vectorizer and calculate the cosine similarity matrix\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(final_data['combined_features'])\n",
        "\n",
        "# Calculate the cosine similarity matrix\n",
        "cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "print(\"Content-based filtering setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhEIZ7LI-_fk",
        "outputId": "de7a0b85-2459-4075-d18c-e1c3cb38a03a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content-based filtering setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader, SVD, dump\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# The Reader class parses the DataFrame, specifying the rating scale.\n",
        "reader = Reader(rating_scale=(1, 10))\n",
        "\n",
        "# Load the DataFrame into the Surprise Dataset format\n",
        "data = Dataset.load_from_df(model_data, reader)\n",
        "\n",
        "# Split the data into a training set and a testing set\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Use the SVD algorithm, a popular matrix factorization technique.\n",
        "algo = SVD()\n",
        "\n",
        "# Train the model on the training data\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "predictions = algo.test(testset)\n",
        "print(\"Model accuracy (RMSE):\")\n",
        "accuracy.rmse(predictions)\n",
        "\n",
        "# Save the trained model to a file for later use in the web app\n",
        "dump.dump('book_recommender_model.pkl', algo=algo)\n",
        "print(\"Collaborative filtering model saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Efv_MvP7ze",
        "outputId": "107fc942-0cc1-4045-93e2-b3fa7ec157f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy (RMSE):\n",
            "RMSE: 1.9423\n",
            "Collaborative filtering model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import dump\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "\n",
        "# --- DEFINE YOUR FILE PATHS HERE ---\n",
        "BOOK_THEMES_PATH = '/content/drive/MyDrive/Colab Notebooks/book recom./BookCrossingThemes.csv'\n",
        "FINAL_DATA_PATH = 'final_data.csv'\n",
        "MODEL_PATH = 'book_recommender_model.pkl'\n",
        "\n",
        "# --- 1. Load Data and Model ---\n",
        "print(\"--- Initializing Hybrid Recommender ---\")\n",
        "try:\n",
        "    df = pd.read_csv(BOOK_THEMES_PATH, sep=';', on_bad_lines='skip', encoding='latin-1')\n",
        "    final_data = pd.read_csv(FINAL_DATA_PATH, index_col=0)\n",
        "    algo = dump.load(MODEL_PATH)[0]\n",
        "    print(\"Files loaded successfully. Setting up content matrix...\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\nCRITICAL ERROR: File not found: {e.filename}.\")\n",
        "    print(\"Please ensure you have run the model training steps (Part 2) and that files are in the /content directory.\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Content Matrix Setup (Memory Optimized) ---\n",
        "df.columns = df.columns.str.strip()\n",
        "final_data.columns = final_data.columns.str.strip()\n",
        "indices = pd.Series(df.index, index=df['Book-Title']).drop_duplicates()\n",
        "features = ['Theme', 'category', 'Book-Author', 'description']\n",
        "\n",
        "for feature in features:\n",
        "    if feature in df.columns:\n",
        "        df[feature] = df[feature].fillna('')\n",
        "def create_combined_features(row):\n",
        "    return ' '.join(str(row[f]) for f in features)\n",
        "df['combined_features'] = df.apply(create_combined_features, axis=1)\n",
        "\n",
        "content_base = final_data[['Book-Title'] + features].drop_duplicates(subset=['Book-Title']).reset_index(drop=True).copy()\n",
        "content_base.columns = content_base.columns.str.strip()\n",
        "content_base['combined_features'] = content_base.apply(create_combined_features, axis=1)\n",
        "indices_small = pd.Series(content_base.index, index=content_base['Book-Title']).drop_duplicates()\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, max_df=0.85)\n",
        "tfidf_matrix_small = tfidf_vectorizer.fit_transform(content_base['combined_features'])\n",
        "cosine_sim_matrix_small = cosine_similarity(tfidf_matrix_small, tfidf_matrix_small)\n",
        "print(\"Content matrix setup complete.\")\n",
        "\n",
        "\n",
        "# --- 3. Hybrid Recommendation Function (Kept for completeness) ---\n",
        "def hybrid_recommendations(user_id, num_recommendations=10, weight_collaborative=0.7, weight_content=0.3):\n",
        "    try:\n",
        "        all_books = df['Book-Title'].unique()\n",
        "        user_rated_books = final_data[final_data['User-ID'] == user_id]['Book-Title'].tolist()\n",
        "\n",
        "        recommendations = []\n",
        "        for book_title in all_books:\n",
        "            if book_title not in user_rated_books:\n",
        "                collab_score = algo.predict(user_id, book_title).est\n",
        "                content_score = 0\n",
        "                if user_rated_books:\n",
        "                    current_book_index = indices_small.get(book_title)\n",
        "\n",
        "                    if current_book_index is not None:\n",
        "                        rated_indices_small = [indices_small[title] for title in user_rated_books if title in indices_small]\n",
        "\n",
        "                        if rated_indices_small and current_book_index < cosine_sim_matrix_small.shape[0]:\n",
        "                            content_scores = [cosine_sim_matrix_small[current_book_index][idx] for idx in rated_indices_small if idx < cosine_sim_matrix_small.shape[1]]\n",
        "                            content_score = np.mean(content_scores) if content_scores else 0\n",
        "\n",
        "                hybrid_score = (weight_collaborative * collab_score) + (weight_content * content_score * 10)\n",
        "                recommendations.append((book_title, hybrid_score))\n",
        "\n",
        "        recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "        return recommendations[:num_recommendations]\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during hybrid recommendation: {e}\")\n",
        "        return []\n",
        "\n",
        "# --- NEW: Content-Based Recommendation by Title ---\n",
        "def get_content_recommendations_by_title(title, num_recommendations=10):\n",
        "    \"\"\"Generates recommendations for a book title based on content similarity.\"\"\"\n",
        "\n",
        "    # Find the best matching title (case-insensitive/partial match for user friendliness)\n",
        "    matches = [t for t in indices_small.index if title.lower().strip() in t.lower()]\n",
        "\n",
        "    if not matches:\n",
        "        return \"Book not found in our popular list. Try another title.\"\n",
        "\n",
        "    # Use the first best match found\n",
        "    title = matches[0]\n",
        "    print(f\"-> Found best match: '{title}'\")\n",
        "\n",
        "    # Get the index of the book in the small matrix\n",
        "    idx = indices_small[title]\n",
        "\n",
        "    # Get the similarity scores for that book with all other books\n",
        "    sim_scores = list(enumerate(cosine_sim_matrix_small[idx]))\n",
        "\n",
        "    # Sort the scores in descending order\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the top N books (excluding the book itself at index 0)\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "\n",
        "    # Get the corresponding book titles and similarity scores\n",
        "    book_indices = [i[0] for i in sim_scores]\n",
        "    similar_titles = content_base['Book-Title'].iloc[book_indices].tolist()\n",
        "    scores = [score[1] for score in sim_scores]\n",
        "\n",
        "    return list(zip(similar_titles, scores))\n",
        "\n",
        "\n",
        "# --- 4. NEW Simple Command Line Interface (CLI) by Title ---\n",
        "if __name__ == '__main__':\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\nEnter Book Title (or 'quit' to exit, e.g., 'The Green Mile'): \")\n",
        "\n",
        "            if user_input.lower() == 'quit':\n",
        "                print(\"Exiting application. Goodbye!\")\n",
        "                break\n",
        "\n",
        "            if not user_input.strip():\n",
        "                continue\n",
        "\n",
        "            print(f\"\\n--- Searching for books similar to '{user_input.strip()}' ---\")\n",
        "            recs = get_content_recommendations_by_title(user_input.strip())\n",
        "\n",
        "            if isinstance(recs, str):\n",
        "                print(f\"ERROR: {recs}\")\n",
        "            elif recs:\n",
        "                print(f\"| Rank | Book Title | Similarity Score |\")\n",
        "                print(f\"| :--- | :--- | :--- |\")\n",
        "                for i, (title, score) in enumerate(recs):\n",
        "                    print(f\"| {i+1} | {title} | {score:.4f} |\")\n",
        "            else:\n",
        "                print(\"Could not generate recommendations for this title.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKBvNUilLaJj",
        "outputId": "86c78e3f-6540-4aaa-d484-cbd7d86de78d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing Hybrid Recommender ---\n",
            "Files loaded successfully. Setting up content matrix...\n",
            "Content matrix setup complete.\n",
            "\n",
            "Enter Book Title (or 'quit' to exit, e.g., 'The Green Mile'): The Green Mile\n",
            "\n",
            "--- Searching for books similar to 'The Green Mile' ---\n",
            "-> Found best match: 'The Green Mile'\n",
            "| Rank | Book Title | Similarity Score |\n",
            "| :--- | :--- | :--- |\n",
            "| 1 | Jurassic Park | 0.2112 |\n",
            "| 2 | Dreamcatcher | 0.2036 |\n",
            "| 3 | Desperation | 0.1659 |\n",
            "| 4 | Pet Sematary | 0.1336 |\n",
            "| 5 | Cause of Death | 0.1027 |\n",
            "| 6 | A Heartbreaking Work of Staggering Genius | 0.0690 |\n",
            "| 7 | The Perfect Storm : A True Story of Men Against the Sea | 0.0614 |\n",
            "| 8 | The Hours: A Novel | 0.0527 |\n",
            "| 9 | The Fellowship of the Ring (The Lord of the Rings, Part 1) | 0.0520 |\n",
            "| 10 | Full House (Janet Evanovich's Full Series) | 0.0251 |\n",
            "\n",
            "Enter Book Title (or 'quit' to exit, e.g., 'The Green Mile'): quit\n",
            "Exiting application. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylc8frxOL_J6",
        "outputId": "7cfb613f-133b-4df0-e653-0c7f6eebfcfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.47.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.9)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gradio as gr\n",
        "from surprise import dump\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings that clutter the interface output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- CONFIGURATION & FILE PATHS ---\n",
        "BOOK_THEMES_PATH = '/content/drive/MyDrive/Colab Notebooks/book recom./BookCrossingThemes.csv'\n",
        "FINAL_DATA_PATH = 'final_data.csv'\n",
        "MODEL_PATH = 'book_recommender_model.pkl' # Model is loaded but not used in this specific content demo\n",
        "\n",
        "# --- 1. Load Data and Model ---\n",
        "print(\"--- Initializing Hybrid Recommender ---\")\n",
        "try:\n",
        "    df = pd.read_csv(BOOK_THEMES_PATH, sep=';', on_bad_lines='skip', encoding='latin-1')\n",
        "    final_data = pd.read_csv(FINAL_DATA_PATH, index_col=0)\n",
        "    # Load model but suppress its output for a clean interface\n",
        "    algo = dump.load(MODEL_PATH)[0]\n",
        "    print(\"Files loaded successfully. Setting up content matrix...\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\nCRITICAL ERROR: File not found: {e.filename}.\")\n",
        "    print(\"Please ensure you have run the model training steps and that files are in the /content directory.\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Content Matrix Setup (Memory Optimized) ---\n",
        "df.columns = df.columns.str.strip()\n",
        "final_data.columns = final_data.columns.str.strip()\n",
        "indices = pd.Series(df.index, index=df['Book-Title']).drop_duplicates()\n",
        "features = ['Theme', 'category', 'Book-Author', 'description']\n",
        "\n",
        "for feature in features:\n",
        "    if feature in df.columns:\n",
        "        df[feature] = df[feature].fillna('')\n",
        "def create_combined_features(row):\n",
        "    return ' '.join(str(row[f]) for f in features)\n",
        "df['combined_features'] = df.apply(create_combined_features, axis=1)\n",
        "\n",
        "content_base = final_data[['Book-Title'] + features].drop_duplicates(subset=['Book-Title']).reset_index(drop=True).copy()\n",
        "content_base.columns = content_base.columns.str.strip()\n",
        "content_base['combined_features'] = content_base.apply(create_combined_features, axis=1)\n",
        "indices_small = pd.Series(content_base.index, index=content_base['Book-Title']).drop_duplicates()\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, max_df=0.85)\n",
        "tfidf_matrix_small = tfidf_vectorizer.fit_transform(content_base['combined_features'])\n",
        "cosine_sim_matrix_small = cosine_similarity(tfidf_matrix_small, tfidf_matrix_small)\n",
        "print(\"Content matrix setup complete. Model ready for Gradio.\")\n",
        "\n",
        "\n",
        "# --- 3. Gradio Interface Function ---\n",
        "def get_recommendations_for_gradio(title):\n",
        "    \"\"\"\n",
        "    Generates recommendations and formats output for Gradio.\n",
        "    This function is wrapped around the core logic.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --- Core Content-Based Logic (from previous steps) ---\n",
        "    title = title.strip()\n",
        "\n",
        "    # Find the best matching title (case-insensitive/partial match for user friendliness)\n",
        "    matches = [t for t in indices_small.index if title.lower() in t.lower()]\n",
        "\n",
        "    if not matches:\n",
        "        return pd.DataFrame({\"Result\": [\"Book not found in our popular list.\"]})\n",
        "\n",
        "    # Use the first best match found\n",
        "    match_title = matches[0]\n",
        "\n",
        "    # Get the index of the book in the small matrix\n",
        "    idx = indices_small[match_title]\n",
        "\n",
        "    # Get the similarity scores for that book with all other books\n",
        "    sim_scores = list(enumerate(cosine_sim_matrix_small[idx]))\n",
        "\n",
        "    # Sort the scores in descending order\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the top 10 books (excluding the book itself at index 0)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # Get the corresponding book titles and similarity scores\n",
        "    book_indices = [i[0] for i in sim_scores]\n",
        "    similar_titles = content_base['Book-Title'].iloc[book_indices].tolist()\n",
        "    scores = [score[1] for score in sim_scores]\n",
        "\n",
        "    # --- Format output for Gradio ---\n",
        "    results_df = pd.DataFrame({\n",
        "        \"#\": range(1, len(similar_titles) + 1), # Changed \"Rank\" to \"#\"\n",
        "        \"Title\": similar_titles,\n",
        "        \"Similarity Score\": [f\"{s:.4f}\" for s in scores],\n",
        "        \"Author\": content_base['Book-Author'].iloc[book_indices].tolist()\n",
        "    })\n",
        "\n",
        "    # Add a header string for display\n",
        "    header_df = pd.DataFrame([{\"#\": f\"Recommended based on match: '{match_title}'\", # Changed \"Rank\" to \"#\"\n",
        "                               \"Title\": \"\", \"Similarity Score\": \"\", \"Author\": \"\"}],\n",
        "                               columns=results_df.columns)\n",
        "\n",
        "    return pd.concat([header_df, results_df], ignore_index=True)\n",
        "\n",
        "\n",
        "# --- 4. Launch Gradio Interface ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Define interface components\n",
        "    input_text = gr.Textbox(label=\"Enter Book Title\", placeholder=\"e.g., The Green Mile, Harry Potter, or a keyword like 'pirates'\")\n",
        "    # Updated headers to use '#'\n",
        "    output_table = gr.Dataframe(label=\"Top 10 Content-Similar Books\", headers=[\"#\", \"Title\", \"Similarity Score\", \"Author\"], row_count=(11, 'fixed'), wrap=True)\n",
        "\n",
        "    # Create the interface block\n",
        "    iface = gr.Interface(\n",
        "        fn=get_recommendations_for_gradio,\n",
        "        inputs=input_text,\n",
        "        outputs=output_table,\n",
        "        title=\"📚 Simple Book Content Recommender\",\n",
        "        description=\"This demo uses TF-IDF and Cosine Similarity (Content-Based Filtering) on themes, categories, and descriptions to find similar books. The final Hybrid model logic is integrated in the application structure.\"\n",
        "    )\n",
        "\n",
        "    # Launch the interface, which creates a public link usable in Colab\n",
        "    iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "u6Kq5jg-Nc8S",
        "outputId": "97474f93-ebc8-46dd-fec5-143c6d291bbe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing Hybrid Recommender ---\n",
            "Files loaded successfully. Setting up content matrix...\n",
            "Content matrix setup complete. Model ready for Gradio.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://82678b034ca783722c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://82678b034ca783722c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-urJx-sDPbAg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}